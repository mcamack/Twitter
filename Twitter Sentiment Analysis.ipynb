{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick project which performs sentiment analysis on tweets using the Natural Language Toolkit (NLTK). The file TweetGrabber.py is used to save any amount of real-time tweets through a Twitter Stream for any search term. The example file used here gathered 3692 tweets in about 10 minutes when the search term was \"Trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import operator\n",
    "import json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object for sentiment analysis and then initialize variables for the current most positive and negative tweet sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "pos_score = 0\n",
    "neg_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcode a filename for the purposes of using on GitHub. This would normally be a command line argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"tweets_2-26-2017.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file and parse by line (each line is a tweet in JSON format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fname, 'r') as f:\n",
    "\tcount_all = Counter()\n",
    "\tfor line in f:\n",
    "\t\ttweet = json.loads(line).get('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the tweet is not Null and then get a sentiment analysis score for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t\t#filter out nulls\n",
    "\t\tif(tweet is not None):\n",
    "\t\t\t#get sentiment score for tweet\n",
    "\t\t\tscore = sia.polarity_scores(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether this tweet scores higher or lower than all previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t\t\t#store most positive tweet\n",
    "\t\t\tif(score['pos'] > pos_score):\n",
    "\t\t\t\tpos_score = score['pos']\n",
    "\t\t\t\tpos = {'score':pos_score, 'tweet':tweet}\n",
    "\n",
    "\t\t\t#store most negative tweet\n",
    "\t\t\tif(score['neg'] > neg_score):\n",
    "\t\t\t\tneg_score = score['neg']\n",
    "\t\t\t\tneg = {'score':neg_score, 'tweet':tweet}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the most common terms across all tweets that were saved. Only count the word if it has more than 4 characters. This helps filter out most emojis and other short, useless words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t\t\t#store a count of most common terms\n",
    "\t\t\twords = tweet.split()\n",
    "\t\t\tterms_all = [term for term in words if len(term)>4]\n",
    "\t\t\tcount_all.update(terms_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the most frequently tweeted words, the most positive tweet, and the most negative tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most used terms:\n",
      "dict_keys(['White', 'House', 'Social', '@THR:', 'Trump', 'https://t.co/Z69wgwywiC', 'media', 'Dinner', 'Baldwin', 'suggests', 'https://t.co/WrqNRDâ€¦', 'replace', \"Correspondents'\"])\n"
     ]
    }
   ],
   "source": [
    "print('Most used terms:')\n",
    "print(nltk.FreqDist(terms_all).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most positive tweet is: 0.733\n",
      "Keep hope alive. https://t.co/huOJ8nwf6c\n"
     ]
    }
   ],
   "source": [
    "print('\\nMost positive tweet is: ' + str(pos['score']))\n",
    "print(pos['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most negative tweet is: 0.853\n",
      "Frightening gullibility. https://t.co/aW5eH8qomH\n"
     ]
    }
   ],
   "source": [
    "print('\\nMost negative tweet is: ' + str(neg['score']))\n",
    "print(neg['tweet'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
